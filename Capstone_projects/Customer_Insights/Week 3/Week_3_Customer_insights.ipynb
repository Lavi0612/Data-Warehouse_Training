{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnDBFLEyYug3",
        "outputId": "986d7dcf-df27-4115-ca5e-3401930d7725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------------------+\n",
            "|               name|delayed_order_count|\n",
            "+-------------------+-------------------+\n",
            "|     Claire Johnson|                  1|\n",
            "|     Marissa Jacobs|                  1|\n",
            "|Christopher Morales|                  2|\n",
            "|     Angelica Miles|                  1|\n",
            "|     Samantha David|                  1|\n",
            "|       Joseph Woods|                  1|\n",
            "|      Anthony Moore|                  1|\n",
            "|    Robert Anderson|                  1|\n",
            "|  Caitlin Rodriguez|                  3|\n",
            "|        Julie Hurst|                  1|\n",
            "|    Sarah Carpenter|                  1|\n",
            "| Catherine Crawford|                  1|\n",
            "|  Kristen Mccormick|                  1|\n",
            "|       Kelsey Miles|                  1|\n",
            "|     Katelyn Nelson|                  1|\n",
            "|  Dr. Tiffany Brady|                  1|\n",
            "|     Jill Robertson|                  1|\n",
            "|        Erika Lopez|                  1|\n",
            "|     Benjamin Lewis|                  2|\n",
            "|     Matthew Snyder|                  1|\n",
            "+-------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Customer Order Insights - Customer Delay Analysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load data\n",
        "customers_df = spark.read.option(\"header\", True).option(\"inferSchema\", True) \\\n",
        "    .csv(\"customers.csv\")\n",
        "\n",
        "orders_df = spark.read.option(\"header\", True).option(\"inferSchema\", True) \\\n",
        "    .csv(\"orders.csv\")\n",
        "\n",
        "delivery_df = spark.read.option(\"header\", True).option(\"inferSchema\", True) \\\n",
        "    .csv(\"delivery_status.csv\")\n",
        "\n",
        "orders_df = orders_df.withColumn(\"order_id\", col(\"order_id\").cast(\"int\")) \\\n",
        "                     .withColumn(\"customer_id\", col(\"customer_id\").cast(\"int\"))\n",
        "\n",
        "delivery_df = delivery_df.withColumn(\"order_id\", col(\"order_id\").cast(\"int\"))\n",
        "\n",
        "# Join datasets\n",
        "orders_with_status = orders_df.join(delivery_df, on=\"order_id\", how=\"inner\")\n",
        "full_data = orders_with_status.join(customers_df, on=\"customer_id\", how=\"inner\")\n",
        "\n",
        "# Filter delayed orders\n",
        "delayed_orders = full_data.filter(col(\"status\") == \"Delayed\")\n",
        "\n",
        "# Group by customer name and count delayed orders\n",
        "delayed_by_customer = delayed_orders.groupBy(\"name\") \\\n",
        "    .count().withColumnRenamed(\"count\", \"delayed_order_count\")\n",
        "\n",
        "# Save result as CSV\n",
        "delayed_by_customer.coalesce(1).write.mode(\"overwrite\") \\\n",
        "    .option(\"header\", True) \\\n",
        "    .csv(\"output/delayed_orders_by_customer\")\n",
        "\n",
        "delayed_by_customer.show()\n",
        "\n",
        "spark.stop()\n"
      ]
    }
  ]
}