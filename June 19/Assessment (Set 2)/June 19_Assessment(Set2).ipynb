{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88ac95c4-e483-49ab-9dde-ecb5c3a85de1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1 Ingestion & Time Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4d6bbf0-c8d9-43e3-b737-7d5700228fa9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+\n|EnrollID|UserID|CourseID|CourseName       |Category    |EnrollDate|CompletionDate|ProgressPercent|Rating|DaysToComplete|\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+\n|E001    |U001  |C001    |Python Basics    |Programming |2024-04-01|2024-04-10    |100            |4     |9             |\n|E002    |U002  |C002    |Excel for Finance|Productivity|2024-04-02|NULL          |45             |NULL  |NULL          |\n|E003    |U001  |C003    |ML with PySpark  |Data Science|2024-04-03|NULL          |30             |NULL  |NULL          |\n|E004    |U003  |C001    |Python Basics    |Programming |2024-04-04|2024-04-20    |100            |5     |16            |\n|E005    |U004  |C004    |Digital Marketing|Marketing   |2024-04-05|2024-04-16    |100            |4     |11            |\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date, datediff\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CourseAnalytics\").getOrCreate()\n",
    "\n",
    "# Load into PySpark with inferred schema\n",
    "enrollments_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"file:/Workspace/Shared/course_enrollments.csv\")\n",
    "\n",
    "# Convert EnrollDate and CompletionDate to date type\n",
    "enrollments_df = enrollments_df \\\n",
    "    .withColumn(\"EnrollDate\", to_date(\"EnrollDate\")) \\\n",
    "    .withColumn(\"CompletionDate\", to_date(\"CompletionDate\"))\n",
    "\n",
    "# Add DaysToComplete column if completed\n",
    "enrollments_df = enrollments_df.withColumn(\"DaysToComplete\", \n",
    "    datediff(\"CompletionDate\", \"EnrollDate\"))\n",
    "\n",
    "enrollments_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56134ee3-e41d-47d9-843a-8ec45337e452",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2 User Learning Path Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a961fd8-b5a2-4f59-84f0-f62ddf9540e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+-----------+\n|UserID|CoursesEnrolled|AvgProgress|\n+------+---------------+-----------+\n|  U004|              1|      100.0|\n|  U002|              1|       45.0|\n|  U003|              1|      100.0|\n|  U001|              2|       65.0|\n+------+---------------+-----------+\n\n+--------+------+---------------+-----------+\n|EnrollID|UserID|ProgressPercent|IsCompleted|\n+--------+------+---------------+-----------+\n|    E001|  U001|            100|       true|\n|    E002|  U002|             45|      false|\n|    E003|  U001|             30|      false|\n|    E004|  U003|            100|       true|\n|    E005|  U004|            100|       true|\n+--------+------+---------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, count, col, when\n",
    "\n",
    "# Count of courses per user + avg progress\n",
    "user_progress = enrollments_df.groupBy(\"UserID\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"CoursesEnrolled\"),\n",
    "        avg(\"ProgressPercent\").alias(\"AvgProgress\")\n",
    "    )\n",
    "\n",
    "# Flag IsCompleted = ProgressPercent = 100\n",
    "enrollments_df = enrollments_df.withColumn(\"IsCompleted\", col(\"ProgressPercent\") == 100)\n",
    "\n",
    "user_progress.show()\n",
    "enrollments_df.select(\"EnrollID\", \"UserID\", \"ProgressPercent\", \"IsCompleted\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6279c59d-17df-4f09-8f80-a3e913d22bb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3 Engagement Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6591dcd7-bf1e-40ed-aee4-d344f2358696",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---------------+------+---------------+\n|EnrollID|UserID|ProgressPercent|Rating|EngagementScore|\n+--------+------+---------------+------+---------------+\n|    E001|  U001|            100|     4|            400|\n|    E002|  U002|             45|     0|              0|\n|    E003|  U001|             30|     0|              0|\n|    E004|  U003|            100|     5|            500|\n|    E005|  U004|            100|     4|            400|\n+--------+------+---------------+------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Replace null Rating with 0 before computing\n",
    "enrollments_df = enrollments_df.fillna({\"Rating\": 0})\n",
    "\n",
    "#Create a score: ProgressPercent * Rating\n",
    "enrollments_df = enrollments_df.withColumn(\"EngagementScore\", \n",
    "    col(\"ProgressPercent\") * col(\"Rating\"))\n",
    "\n",
    "enrollments_df.select(\"EnrollID\", \"UserID\", \"ProgressPercent\", \"Rating\", \"EngagementScore\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b75c0fad-43a6-4e16-b006-80b9d1f3e11b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4 Identify Drop-offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c26f4026-a729-4640-8c33-ebc827bec09b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+---------------+\n|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|DaysToComplete|EngagementScore|\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+---------------+\n|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|     0|          NULL|              0|\n|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|     0|          NULL|              0|\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "#Filter all records with ProgressPercent < 50 and CompletionDate is null\n",
    "dropouts_df = enrollments_df.filter(\n",
    "    (col(\"ProgressPercent\") < 50) & (col(\"CompletionDate\").isNull())\n",
    ")\n",
    "\n",
    "#Create a view called Dropouts\n",
    "dropouts_df.createOrReplaceTempView(\"Dropouts\")\n",
    "spark.sql(\"SELECT * FROM Dropouts\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd6874bb-d142-4878-9900-e80b54e8fd68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "5 Joins with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36dd13d8-cf78-4ab1-81e1-b5b8e851a2e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n|   Instructor|AvgProgress|\n+-------------+-----------+\n|  Zoya Sheikh|      100.0|\n|   Sana Gupta|       45.0|\n| Ibrahim Khan|       30.0|\n|Abdullah Khan|      100.0|\n+-------------+-----------+\n\n+-------------+-------------+----------------+\n|   CourseName|   Instructor|TotalEnrollments|\n+-------------+-------------+----------------+\n|Python Basics|Abdullah Khan|               2|\n+-------------+-------------+----------------+\nonly showing top 1 row\n\n"
     ]
    }
   ],
   "source": [
    "catalog_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"file:/Workspace/Shared/course_catalog.csv\")\n",
    "\n",
    "joined_df = enrollments_df.join(catalog_df, \"CourseID\")\n",
    "\n",
    "# Join to find average progress per instructor\n",
    "joined_df.groupBy(\"Instructor\").agg(avg(\"ProgressPercent\").alias(\"AvgProgress\")).show()\n",
    "\n",
    "# Show who teaches the most enrolled course\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "most_enrolled = joined_df.groupBy(\"CourseName\", \"Instructor\") \\\n",
    "    .agg(count(\"*\").alias(\"TotalEnrollments\")) \\\n",
    "    .orderBy(col(\"TotalEnrollments\").desc())\n",
    "\n",
    "most_enrolled.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6decc083-7c61-44d5-ae15-67431d33e844",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "6 Delta Lake Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1e8a064-e4ba-496a-8fca-2bdc7029f4c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----------------+--------------------+---------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n|version|          timestamp|          userId|            userName|operation| operationParameters| job|          notebook|           clusterId|readVersion|   isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n+-------+-------------------+----------------+--------------------+---------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n|      3|2025-06-19 05:26:33|4028198190791787|azuser3553_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{1052067078041127}|0611-043506-43vn1hs6|          1|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n|      2|2025-06-19 05:26:31|4028198190791787|azuser3553_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{1052067078041127}|0611-043506-43vn1hs6|          1|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n|      1|2025-06-19 05:26:30|4028198190791787|azuser3553_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{1052067078041127}|0611-043506-43vn1hs6|          0|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n|      0|2025-06-19 05:26:27|4028198190791787|azuser3553_mml.lo...|    WRITE|{mode -> Overwrit...|NULL|{1052067078041127}|0611-043506-43vn1hs6|       NULL|WriteSerializable|        false|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n+-------+-------------------+----------------+--------------------+---------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Save as Delta Table enrollments_delta\n",
    "enrollments_df.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/enrollments_delta\")\n",
    "\n",
    "delta_table = DeltaTable.forPath(spark, \"/tmp/enrollments_delta\")\n",
    "\n",
    "# Update: Set all ratings to 5 where Course = 'Python Basics'\n",
    "delta_table.update(\n",
    "    condition=\"CourseName = 'Python Basics'\",\n",
    "    set={\"Rating\": \"5\"}\n",
    ")\n",
    "\n",
    "# Delete: All rows where ProgressPercent = 0\n",
    "delta_table.delete(\"ProgressPercent = 0\")\n",
    "\n",
    "# Show describe history\n",
    "spark.sql(\"DESCRIBE HISTORY delta.`/tmp/enrollments_delta`\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdc97524-e23c-48f4-8c70-d13e16cee270",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "7 Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c82c056-8fa5-4941-b8c3-477aa10c8253",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+----------------+----+\n|CourseID|       CourseName|TotalEnrollments|Rank|\n+--------+-----------------+----------------+----+\n|    C001|    Python Basics|               2|   1|\n|    C004|Digital Marketing|               1|   2|\n|    C002|Excel for Finance|               1|   2|\n|    C003|  ML with PySpark|               1|   2|\n+--------+-----------------+----------------+----+\n\n+------+--------+----------+------------+\n|UserID|CourseID|EnrollDate|NextCourseID|\n+------+--------+----------+------------+\n|  U001|    C001|2024-04-01|        C003|\n|  U001|    C003|2024-04-03|        NULL|\n|  U002|    C002|2024-04-02|        NULL|\n|  U003|    C001|2024-04-04|        NULL|\n|  U004|    C004|2024-04-05|        NULL|\n+------+--------+----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import dense_rank, lead\n",
    "\n",
    "# Use dense_rank() to rank courses by number of enrollments\n",
    "course_rank_window = Window.orderBy(col(\"TotalEnrollments\").desc())\n",
    "\n",
    "course_counts = enrollments_df.groupBy(\"CourseID\", \"CourseName\") \\\n",
    "    .agg(count(\"*\").alias(\"TotalEnrollments\")) \\\n",
    "    .withColumn(\"Rank\", dense_rank().over(course_rank_window))\n",
    "\n",
    "course_counts.show()\n",
    "\n",
    "# lead() to find next course by each user\n",
    "lead_window = Window.partitionBy(\"UserID\").orderBy(\"EnrollDate\")\n",
    "enrollments_df = enrollments_df.withColumn(\"NextCourseID\", lead(\"CourseID\").over(lead_window))\n",
    "\n",
    "enrollments_df.select(\"UserID\", \"CourseID\", \"EnrollDate\", \"NextCourseID\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfd7e5fa-61b4-4d9b-ac3a-8e5708eb6f76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "8 SQL Logic for Dashboard Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5c8dffa-7275-4a3e-8af2-75b6c7604f31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n| EnrollDay|count|\n+----------+-----+\n|2024-04-02|    1|\n|2024-04-01|    1|\n|2024-04-04|    1|\n|2024-04-05|    1|\n|2024-04-03|    1|\n+----------+-----+\n\n+------------+---------+\n|    Category|AvgRating|\n+------------+---------+\n| Programming|      4.5|\n|Productivity|      0.0|\n|   Marketing|      4.0|\n|Data Science|      0.0|\n+------------+---------+\n\n+-----------------+----------------+\n|       CourseName|TotalEnrollments|\n+-----------------+----------------+\n|    Python Basics|               2|\n|Digital Marketing|               1|\n|Excel for Finance|               1|\n+-----------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date, avg\n",
    "\n",
    "# Daily enrollments\n",
    "enrollments_df.withColumn(\"EnrollDay\", to_date(\"EnrollDate\")) \\\n",
    "    .groupBy(\"EnrollDay\").count().createOrReplaceTempView(\"daily_enrollments\")\n",
    "\n",
    "# Category performance\n",
    "enrollments_df.groupBy(\"Category\") \\\n",
    "    .agg(avg(\"Rating\").alias(\"AvgRating\")) \\\n",
    "    .createOrReplaceTempView(\"category_performance\")\n",
    "\n",
    "# Create a temporary view for course enrollments\n",
    "enrollments_df.createOrReplaceTempView(\"course_enrollments\")\n",
    "\n",
    "# Top 3 courses by enrollments\n",
    "spark.sql(\"\"\"\n",
    "    SELECT CourseName, COUNT(*) as TotalEnrollments\n",
    "    FROM course_enrollments\n",
    "    GROUP BY CourseName\n",
    "    ORDER BY TotalEnrollments DESC\n",
    "    LIMIT 3\n",
    "\"\"\").createOrReplaceTempView(\"top_3_courses\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM daily_enrollments\").show()\n",
    "spark.sql(\"SELECT * FROM category_performance\").show()\n",
    "spark.sql(\"SELECT * FROM top_3_courses\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e71ef853-eb7f-47c8-937d-64c089885d21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "9 Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "300b63ec-bd3c-4993-9aac-18f918be6976",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+---------------+\n|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|DaysToComplete|EngagementScore|\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+---------------+\n|    E001|  U001|    C001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|     4|             9|            400|\n|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|     0|          NULL|              0|\n|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|     0|          NULL|              0|\n|    E004|  U003|    C001|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|     5|            16|            500|\n|    E005|  U004|    C004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|     4|            11|            400|\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "# View previous version before update/delete\n",
    "spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"/tmp/enrollments_delta\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f9d0bd3-69e3-4030-b974-b448d77bd96b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "10 Export Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d060b16c-96f3-488b-b2f3-8c3b88c73ed7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+---------+-----------+\n|       CourseName|TotalEnrollments|AvgRating|AvgProgress|\n+-----------------+----------------+---------+-----------+\n|Digital Marketing|               1|      4.0|      100.0|\n|    Python Basics|               2|      4.5|      100.0|\n|Excel for Finance|               1|      0.0|       45.0|\n|  ML with PySpark|               1|      0.0|       30.0|\n+-----------------+----------------+---------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "#Write to JSON, partitioned by Category\n",
    "enrollments_df.write.mode(\"overwrite\").partitionBy(\"Category\").json(\"output/enrollments_json\")\n",
    "\n",
    "#Create summary DataFrame \n",
    "summary_df = enrollments_df.groupBy(\"CourseName\").agg(\n",
    "    count(\"*\").alias(\"TotalEnrollments\"),\n",
    "    avg(\"Rating\").alias(\"AvgRating\"),\n",
    "    avg(\"ProgressPercent\").alias(\"AvgProgress\")\n",
    ")\n",
    "\n",
    "summary_df.show()\n",
    "\n",
    "#Save as parquet\n",
    "summary_df.write.mode(\"overwrite\").parquet(\"output/course_summary_parquet\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "June 19_Assessment(Set2)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}